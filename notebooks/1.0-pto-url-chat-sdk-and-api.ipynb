{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/') \n",
    "from url_chat import URLChat\n",
    "\n",
    "from haystack.components.preprocessors import DocumentSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_chat = URLChat(split_by=\"sentence\", split_length=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on URLChat in module url_chat object:\n",
      "\n",
      "class URLChat(builtins.object)\n",
      " |  URLChat(llm_model: str = 'llama3', split_by: str = 'sentence', split_length: int = 15)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, llm_model: str = 'llama3', split_by: str = 'sentence', split_length: int = 15)\n",
      " |      Model that answers questions based on the content of a given URL\n",
      " |      \n",
      " |      Args:\n",
      " |          llm_model (str, optional): LLM used for text generation. Defaults to \"llama3\".\n",
      " |          split_by (str, optional): Splits the document from the URL into smaller parts before indexing. \n",
      " |              Can split by \"word\", \"sentence\", \"passage\" (paragraph), or \"page\". Defaults to \"sentence\".\n",
      " |          split_length (int, optional): The chunk size, which is the number of words, sentences, or passages. Defaults to 15.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: User must choose one of the available LLM: 'llama3', 'mixtral', 'gemma', 'gemma2', 'whisper'\n",
      " |  \n",
      " |  ask(self, url: str, question: str) -> dict\n",
      " |      Send a url that has been previously indexed using the _index_ method and a question relating to it.\n",
      " |      \n",
      " |      Args:\n",
      " |          url (str): a url that has been previously indexed using _index_ method. Example: \"https://en.wikipedia.org/wiki/Brazil\"\n",
      " |          question (str): a question relating to the url. Example: \"What is the population of Brazil\"\n",
      " |          \n",
      " |      Returns:\n",
      " |          dict: A dictionary containing the reply generated by the model and metadata on the model.\n",
      " |  \n",
      " |  build_ask_pipeline(self, retriever, prompt_builder, llm)\n",
      " |  \n",
      " |  build_index_pipeline(self, fetcher, converter, preprocessor, document_writer)\n",
      " |  \n",
      " |  index(self, url: str)\n",
      " |      Send a url so that the model extracts and indexes its content\n",
      " |      \n",
      " |      Args:\n",
      " |          url (str): full URL. Example: \"https://en.wikipedia.org/wiki/Brazil\"\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(url_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_chat.index(\"https://haystack.deepset.ai/\")\n",
    "url_chat.index(\"https://huggingface.co/\")\n",
    "url_chat.index(\"https://en.wikipedia.org/wiki/Brazil\")\n",
    "url_chat.index(\"https://en.wikipedia.org/wiki/New_York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'replies': ['According to the text, the population of Brazil is approximately 205,375,043 (as of 2024) and 203,080,756 (as of 2022).'],\n",
       " 'meta': [{'model': 'llama3-8b-8192',\n",
       "   'index': 0,\n",
       "   'finish_reason': 'stop',\n",
       "   'usage': {'completion_tokens': 39,\n",
       "    'prompt_tokens': 4843,\n",
       "    'total_tokens': 4882,\n",
       "    'prompt_time': 0.736391191,\n",
       "    'completion_time': 0.030618088,\n",
       "    'total_time': 0.7670092789999999}}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_chat.ask(\"https://en.wikipedia.org/wiki/Brazil\", \"what is the population of Brazil?\")\n",
    "# url_chat.ask(\"https://en.wikipedia.org/wiki/Brazil\", \"when was the Treaty of Tordesillas?\")\n",
    "# url_chat.ask(\"https://en.wikipedia.org/wiki/New_York\", \"where is ny?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API\n",
    "\n",
    "**Run this from the folder src/ containing api.py**\n",
    "\n",
    "```\n",
    "uvicorn api:app --reload --port 8001\n",
    "curl -X POST \"http://127.0.0.1:8001/index-url/\" -H \"Content-Type: application/json\" -d '{\"url\": \"https://en.wikipedia.org/wiki/Brazil\"}'\n",
    "curl -X POST \"http://127.0.0.1:8001/ask/\" -H \"Content-Type: application/json\" -d '{\"url\": \"https://en.wikipedia.org/wiki/Brazil\", \"question\": \"what is the population of Brazil?\"}'\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
